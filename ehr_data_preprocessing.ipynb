{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ehr_data_preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxpvuZzH2hwH",
        "outputId": "5491ba01-0a42-472c-8618-623f6d4dd77e"
      },
      "source": [
        "!pip install pypdf2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pypdf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/01/68fcc0d43daf4c6bdbc6b33cc3f77bda531c86b174cac56ef0ffdb96faab/PyPDF2-1.26.0.tar.gz (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 21.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 14.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pypdf2\n",
            "  Building wheel for pypdf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypdf2: filename=PyPDF2-1.26.0-cp37-none-any.whl size=61102 sha256=dfc19e938d2bbbee665e376ef5358165fb868ad2b70f0518f077d075778fa7b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/84/19/35bc977c8bf5f0c23a8a011aa958acd4da4bbd7a229315c1b7\n",
            "Successfully built pypdf2\n",
            "Installing collected packages: pypdf2\n",
            "Successfully installed pypdf2-1.26.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxQ0gvsc3nQw"
      },
      "source": [
        "import PyPDF2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7nl94AQ5mC8"
      },
      "source": [
        "import csv\n",
        "import datetime\n",
        "import numpy\n",
        "import scipy\n",
        "import scipy.sparse\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HcKpgMG5mI-"
      },
      "source": [
        "def _build_patient_mapping(patients):\n",
        "  \"\"\"\n",
        " Create a mapping of the patient identifier to an index\n",
        " \"\"\"\n",
        "  pmap = {}\n",
        "  for ii in range(len(patients)):\n",
        "    pmap[patients[ii]] = ii\n",
        "  return patmap\n",
        "def _build_feature_mapping(features):\n",
        "  \"\"\"\n",
        " Create a mapping of the feature name to an index\n",
        " \"\"\"\n",
        "  fmap = {}\n",
        "  for ii in range(len(features)):\n",
        "    fmap[features[ii]] = ii\n",
        "  return fmap\n",
        "t0 = datetime.datetime.strptime('01/01/1900', \"%m/%d/%Y\")\n",
        "\n",
        "def _map_time_to_dayId(time):\n",
        "  \"\"\"\n",
        " Convert datetime into an integer day offset from some base date (01-01-1900)\n",
        " to facilitate date difference computations.\n",
        " \"\"\"\n",
        "  t = datetime.datetime.strptime(time, \"%m/%d/%Y\")\n",
        "  d = t - t0\n",
        "  return d.days"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkC-unLbGSnj"
      },
      "source": [
        "def loadPatientCohortDataFile(fileName):\n",
        "  \"\"\"\n",
        " Read in a patient cohort data file with columns: patientId, label, operational\n",
        "Date (yyyy-mm-dd format)\n",
        " label is 0 for controls and 1 for cases\n",
        " operationalDate for cases is the diagnosis date\n",
        " operationalDate for controls is the diagnosis date for the matching control\n",
        " 627,0,2001-07-28\n",
        " 628,0,2001-07-28\n",
        " 629,1,2004-11-14\n",
        " 639,1,2004-02-19\n",
        " Generate 3 mappings\n",
        " pidMap: patientId -> integer (offset)\n",
        " labelMap: patientId -> label\n",
        " dateIdMap: patientId -> operationalDateId\n",
        " \"\"\"\n",
        "# Load raw data\n",
        "  pdf = open(fileName, 'rb')\n",
        "  pdfReader = PyPDF2.PdfFileReader(pdf)\n",
        "  num_pages=pdfReader.numPages\n",
        "  n=0\n",
        "  pidMap = {}\n",
        "  labelMap = {}\n",
        "  dateIdMap = {}\n",
        "\n",
        "  for i in range(num_pages):\n",
        "    page=pdfReader.getPage(i)\n",
        "    lines=page.extractText().split(\"\\n\")\n",
        "    j=0\n",
        "    while j < (len(lines))-1:\n",
        "      pidMap[int(lines[j])]=n\n",
        "      labelMap[int(lines[j])]=int(lines[j+1])\n",
        "      dateIdMap[int(lines[j])]=int(_map_time_to_dayId(lines[j+2]))\n",
        "      n+=1\n",
        "      j+=3\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Return results\n",
        "  return pidMap, labelMap, dateIdMap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_aIgSZX5kc3"
      },
      "source": [
        "def loadPatientDataFile(fileName):\n",
        "  \"\"\"\n",
        " Read input data with columns: patientId, date (yyyy-mm-dd format), featureName\n",
        ", featureValue\n",
        " 627,1998-11-08,DIAGNOSIS:401.9,1.0\n",
        " 627,1999-05-21,DIAGNOSIS:401.9,1.0\n",
        " 628,1998-09-30,DIAGNOSIS:401.9,1.0\n",
        " 628,1998-11-01,DIAGNOSIS:401.9,1.0\n",
        " 627,1999-08-07,ACE_Inhibitors:ACE_Inhibitors,1.0\n",
        " 627,1999-12-04,Angiotensin_II_Receptor_Antagonists,1.0\n",
        " 627,1999-12-04,Loop_Diuretics,1.0\n",
        " 627,2000-06-11,Beta_Blockers_Cardio-Selective,1.0\n",
        " 628,1998-09-30,Antiadrenergic_Antihypertensives,1.0\n",
        " 628,1998-11-01,Antiadrenergic_Antihypertensives,1.0\n",
        " 627,2000-06-11,Vital:BloodPressure:DIAS_BP,70.0\n",
        " 627,2000-06-11,Vital:BloodPressure:SYS_BP,142.0\n",
        " 628,1998-09-30,Vital:BloodPressure:DIAS_BP,78.0\n",
        " 628,1998-09-30,Vital:BloodPressure:SYS_BP,142.0\n",
        " Convert it into a numeric matrix format with columns: patientId, dateId, featu\n",
        "reId, featureValue\n",
        "  \"\"\"\n",
        "  pdfFileObj = open(fileName, 'rb')\n",
        "  data=[]\n",
        "  features=[]\n",
        "  pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
        "  for i in range(pdfReader.numPages):\n",
        "    lines=pdfReader.getPage(i).extractText()\n",
        "    lines=lines.split(\"\\n\")\n",
        "    j=0\n",
        "    while j<len(lines)-1:\n",
        "      d=[int(lines[j]),int(_map_time_to_dayId(lines[j+1])),lines[j+2],int(lines[j+3])]\n",
        "      data.append(d)\n",
        "      features.append(lines[j+2])\n",
        "      j+=4\n",
        "    feature_map=_build_feature_mapping(list(set(features)))\n",
        "  for i in range(len(data)):\n",
        "    data[i][2]=int(feature_map[data[i][2]])\n",
        "  return np.asarray(data),feature_map\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohgkJibzBMt7"
      },
      "source": [
        "def computeFeature_boolean(A, pw, ow, pidMap, featureMap, opDateMap):\n",
        "  \"\"\"\n",
        " Compute a boolean of all the data in A specified by the prediction window, obs\n",
        "ervation window, and operational date\n",
        " A: patientId dateId featureId featureValue\n",
        " pw: prediction window\n",
        " ow: observation window\n",
        " pidMap: dictionary mapping of patientId -> row offset\n",
        " featureMap : dictionary mapping of featureName -> column offset\n",
        " opDateMap: dictionary mapping of patientId -> operationalDateId\n",
        " \"\"\"\n",
        "  np = len(pidMap)\n",
        "  nf = len(featureMap)\n",
        "  M = scipy.sparse.lil_matrix((np, nf))\n",
        "\n",
        "  for ii in range(A.shape[0]):\n",
        "    if A[ii, 0] in pidMap:\n",
        "      pid = pidMap[int(A[ii, 0])]\n",
        "      fid = int(A[ii, 2])\n",
        "      opd = opDateMap[int(A[ii, 0])]\n",
        "\n",
        "      val = A[ii, 3]\n",
        "      if (A[ii, 1] > (opd - ow - pw)) and (A[ii, 1] < (opd - pw)):\n",
        "        if pid >= 0:\n",
        "          if val > 0:\n",
        "            M[pid, fid] = 1.0\n",
        "\n",
        "  M = M.tocsc()\n",
        "  return M\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtCgyGg94D3h"
      },
      "source": [
        "def computeFeature_count(A, pw, ow, pidMap, featureMap, opDateMap):\n",
        "  \"\"\"\n",
        " Compute the count of all the data in A specified by the prediction window, obs\n",
        "ervation window, and operational date\n",
        " A: patientId dateId featureId featureValue\n",
        " pw: prediction window\n",
        " ow: observation window\n",
        " pidMap: dictionary mapping of patientId -> row offset\n",
        " featureMap : dictionary mapping of featureName -> column offset\n",
        " opDateMap: dictionary mapping of patientId -> operationalDateId\n",
        " \"\"\"\n",
        "  np = len(pidMap)\n",
        "  nf = len(featureMap)\n",
        "  M = scipy.sparse.lil_matrix((np, nf))\n",
        "\n",
        "  for ii in range(A.shape[0]):\n",
        "    if A[ii, 0] in pidMap:\n",
        "      pid = pidMap[(A[ii, 0])]\n",
        "      fid = int(A[ii, 2])\n",
        "      opd = opDateMap[int(A[ii, 0])]\n",
        "\n",
        "      val = A[ii, 3]\n",
        "      if (A[ii, 1] > (opd - ow - pw)) and (A[ii, 1] < (opd - pw)):\n",
        "        if pid >= 0:\n",
        "          if val > 0:\n",
        "            M[pid, fid] = M[pid, fid] + 1.0\n",
        "\n",
        "  M = M.tocsc()\n",
        "  return M\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxihgyhE6TKS"
      },
      "source": [
        "def computeFeature_mean(A, pw, ow, pidMap, featureMap, opDateMap):\n",
        "  \"\"\"\n",
        " Compute the mean of all the data in A specified by the prediction window, obse\n",
        "rvation window, and operational date\n",
        " A: patientId dateId featureId featureValue\n",
        " pw: prediction window\n",
        " ow: observation window\n",
        " pidMap: dictionary mapping of patientId -> row offset\n",
        " featureMap : dictionary mapping of featureName -> column offset\n",
        " opDateMap: dictionary mapping of patientId -> operationalDateId\n",
        " \"\"\"\n",
        "  v = A[:, 2]\n",
        "  uv = numpy.unique(v)\n",
        "  nuv = len(uv)\n",
        "  min_v = numpy.zeros((nuv, 1))\n",
        "  max_v = numpy.zeros((nuv, 1))\n",
        "  for ii in range(nuv):\n",
        "    fv = int(uv[ii])\n",
        "    idx = numpy.nonzero(v.astype(int) == fv)[0]\n",
        "    vv = A[idx, 3]\n",
        "    svv = numpy.sort(vv)\n",
        "    nsvv = numpy.size(svv)\n",
        "    min_v[ii] = svv[int(numpy.floor(nsvv * 0.1))]\n",
        "    max_v[ii] = svv[int(numpy.floor(nsvv * 0.9))]\n",
        "    min_v[ii] = max(0, min_v[ii])\n",
        "  features = uv\n",
        "\n",
        "  np = len(pidMap)\n",
        "  nf = len(featureMap)\n",
        "  M = scipy.sparse.lil_matrix((np, nf))\n",
        "  Mn = scipy.sparse.lil_matrix((np, nf))\n",
        "  for ii in range(A.shape[0]):\n",
        "    if A[ii, 0] in pidMap:\n",
        "      pid = pidMap[int(A[ii, 0])]\n",
        "      fid = int(A[ii, 2])\n",
        "      opd = opDateMap[int(A[ii, 0])]\n",
        "      if (A[ii, 1] > (opd - ow - pw)) and (A[ii, 1] < (opd - pw)):\n",
        "        if (A[ii, 3] <= max_v[fid]) and (A[ii, 3] >= min_v[fid]):\n",
        "          if pid >= 0:\n",
        "            Mn[pid, fid] += 1\n",
        "            delta = A[ii, 3] - M[pid, fid]\n",
        "            M[pid, fid] += delta / Mn[pid, fid]\n",
        "\n",
        "# Populate missing values\n",
        "  for i in range(np):\n",
        "    for j in range(nf):\n",
        "      if Mn[i,j] == 0:\n",
        "        M[i,j] = numpy.nan\n",
        "\n",
        "  M = M.tocsc()\n",
        "  return M\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlK2u6s_VNS5"
      },
      "source": [
        "def constructFeatures(cohortFile, dataFile, outputFile, predictionWindow=365, observationWindow=730, aggregationMethod=\"boolean\"):\n",
        "  \"\"\"\n",
        "  Compute features for the patients listed in the cohortFile using the longitudi\n",
        "  nal data in dataFile.\n",
        "  Use the specified predictionWindow and observationWindow values to determine w\n",
        "  hat patient data to use.\n",
        "  Use the specified aggregation method (boolean, count, mean) to generate the su\n",
        "  mmary value of the features.\n",
        " \"\"\"\n",
        "  # Load the data\n",
        "  pidMap, labelMap, opDateMap = loadPatientCohortDataFile(cohortFile)\n",
        "  data, featureMap = loadPatientDataFile(dataFile)\n",
        "\n",
        "# Compute the feature vector matrix\n",
        "  M = None\n",
        "  if aggregationMethod == 'mean':\n",
        "    M = computeFeature_mean(data, predictionWindow, observationWindow, pidMap,featureMap, opDateMap)\n",
        "  elif aggregationMethod == 'count':\n",
        "    M = computeFeature_count(data, predictionWindow, observationWindow, pidMap, featureMap, opDateMap)\n",
        "  elif aggregationMethod == 'boolean':\n",
        "    M = computeFeature_boolean(data, predictionWindow, observationWindow, pidMap, featureMap, opDateMap)\n",
        "  else:\n",
        "    print ('Aggregation Method Unknown: ', aggregationMethod)\n",
        "\n",
        "# Write out feature vector matrix with the patient id and label columns and header\n",
        "  outfile = open(outputFile, 'w')\n",
        "  outwriter = csv.writer(outfile)\n",
        "  header = ['patientId', 'label']\n",
        "  fList = sorted(featureMap, key=featureMap.get)\n",
        "  header.extend(fList)\n",
        "  outwriter.writerow(header)\n",
        "\n",
        "# Get the patient id list\n",
        "  pidList = sorted(pidMap, key=pidMap.get)\n",
        "\n",
        "# Write out one row for each patient\n",
        "  print (M.shape)\n",
        "  nrows, ncols = M.shape\n",
        "  for n in range(nrows):\n",
        "    pid = pidList[n]\n",
        "    label = labelMap[pid]\n",
        "    rowData = [pid, label]\n",
        "    for m in range(ncols):\n",
        "      rowData.append(M[n,m])\n",
        "    outwriter.writerow(rowData)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPogEXaxXVKW",
        "outputId": "f165ad7a-1778-4344-97bc-49c7591dc193"
      },
      "source": [
        "# Construct the features from the diagnosis data aggreation_method=boolean\n",
        "dataFile = \"/content/daignosis_record.pdf\"\n",
        "diagnosisOutputFile = \"/content/\"+ 'output_diagnosis.csv'\n",
        "cohortFile=\"/content/patient_cohort.pdf\"\n",
        "constructFeatures(cohortFile, dataFile, diagnosisOutputFile, predictionWindow=365,\n",
        "observationWindow=730, aggregationMethod=\"boolean\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWD5iDpfeRQ8",
        "outputId": "57de68c0-408e-4576-937a-b8a9b2db167c"
      },
      "source": [
        "# Construct the features for the medication data\n",
        "baseDirectory = '/content/'\n",
        "cohortFile = \"/content/patient_cohort.pdf\"\n",
        "dataFile = \"/content/medication_record.pdf\"\n",
        "medicationOutputFile = baseDirectory + 'output_medication.csv'\n",
        "constructFeatures(cohortFile, dataFile, medicationOutputFile, predictionWindow=365\n",
        ", observationWindow=730, aggregationMethod=\"count\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 51)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0gjU4kzgl7p",
        "outputId": "43cc1d18-5596-442d-a9a4-40788ad8023c"
      },
      "source": [
        "# Construct the features for the vitals data\n",
        "dataFile = \"/content/vitals_record.pdf\"\n",
        "vitalsOutputFile = baseDirectory + 'output_vital.csv'\n",
        "constructFeatures(cohortFile, dataFile, vitalsOutputFile, predictionWindow=365, observationWindow=730, aggregationMethod=\"mean\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peaE3bEohLUD"
      },
      "source": [
        "def combineFeatures(outputFile, *featureFiles):\n",
        "  \"\"\"\n",
        " Combines the feature files (generated by constructFeatures) into one file base\n",
        "d on patientId\n",
        " Will only keep one patientId and Label column\n",
        " \"\"\"\n",
        "  data = {}\n",
        "  header = ['patientId', 'label']\n",
        "  for f in featureFiles:\n",
        "    csvReader = csv.reader(open(f), delimiter=',', quotechar='\"')\n",
        "    i = 0\n",
        "    for x in csvReader:\n",
        "# Header line\n",
        "      if i == 0:\n",
        "        featureNames = x[2:]\n",
        "        header.extend(featureNames)\n",
        "      else:\n",
        "        pid = x[0]\n",
        "        label = x[1]\n",
        "        featureValues = x[2:]\n",
        "        if not (pid in data):\n",
        "          data[pid] = [pid, label]\n",
        "        data[pid].extend(featureValues)\n",
        "      i = i + 1\n",
        "\n",
        "# Output combined data\n",
        "  outfile = open(outputFile, 'w')\n",
        "  outwriter = csv.writer(outfile)\n",
        "  outwriter.writerow(header)\n",
        "  for pid in sorted(data.keys()):\n",
        "    outwriter.writerow(data[pid])\n",
        "  print (len(data), len(data[pid]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4d-qvXiinJX",
        "outputId": "22ae74ad-7397-4cec-8b4e-05b30e786e73"
      },
      "source": [
        "# Combine the features into one file\n",
        "allOutputFile = baseDirectory + 'output_all.csv'\n",
        "combineFeatures(allOutputFile, vitalsOutputFile, diagnosisOutputFile, medicationOutputFile)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500 61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb_Z1dQKivaI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}